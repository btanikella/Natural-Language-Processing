{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is project 2, which focuses on sequence labeling. Please use this notebook to submit your answers,\n",
      "and make sure you code runs inside the notebook. If you need to include .py files with your submission,\n",
      "please make sure to do so."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import Python package here\n",
      "import scorer\n",
      "import numpy as np\n",
      "import pylab as pl\n",
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 1 Data Processing #\n",
      "\n",
      "Download the train data and dev data from [Github](https://github.com/jacobeisenstein/gt-nlp-class/tree/master/projects/proj-2). \n",
      "The test data will be released around 48 hours before the deadline.\n",
      "The part-of-speech tags are defined in the [ACL2011 paper](http://www.ark.cs.cmu.edu/TweetNLP/gimpel+etal.acl11.pdf) \n",
      "and the [NAACL 2013 paper](http://www.ark.cs.cmu.edu/TweetNLP/owoputi+etal.naacl13.pdf), \n",
      "which also describe the data and gives some state-of-art results."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Data processing code\n",
      "\"\"\"\n",
      "def conllSeqGenerator(input_file,max_insts=1000000):\n",
      "    \"\"\" return an instance generator for a filename\n",
      "    \n",
      "    The generator yields lists of words and tags.  \n",
      "    \"\"\"\n",
      "    cur_words = []\n",
      "    cur_tags = []\n",
      "    num_insts = 0\n",
      "    with open(input_file) as instances:\n",
      "        for line in instances:\n",
      "            if len(line.rstrip()) == 0:\n",
      "                if len(cur_words) > 0:\n",
      "                    num_insts += 1\n",
      "                    yield cur_words,cur_tags\n",
      "                    cur_words = []\n",
      "                    cur_tags = []\n",
      "            else:\n",
      "                parts = line.rstrip().split()\n",
      "                cur_words.append(parts[0])\n",
      "                if len(parts)>1:\n",
      "                    cur_tags.append(parts[1])\n",
      "                else: cur_tags.append(unk)\n",
      "        if len(cur_words)>0: \n",
      "            num_insts += 1\n",
      "            yield cur_words,cur_tags"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Define the file names\n",
      "trainfile = 'oct27.train'\n",
      "devfile = 'oct27.dev'\n",
      "testfile = 'oct27.test' # You do not have this for now"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here is a demo code for using function \"conllSeqGenerator()\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Demo\n",
      "alltags = set()\n",
      "for counter,(words, tags) in enumerate(conllSeqGenerator(trainfile)):    \n",
      "    for tag in tags:\n",
      "        alltags.add(tag)\n",
      "print alltags"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "set(['!', '#', '$', '&', ',', 'A', '@', 'E', 'D', 'G', 'M', 'L', 'O', 'N', 'P', 'S', 'R', 'U', 'T', 'V', 'Y', 'X', 'Z', '^', '~'])\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 2 Supervised Classification #\n",
      "\n",
      "Apply your classifiers from last time to perform supervised classification. The input is the word to be tagged; the output is the tag. You can use the  *score.py* script again to compute accuracy. \n",
      "\n",
      "If you augmented your classifier in some way (like MIRA), you may use this augmentation. Do **NOT** perform any stemming, downcasing or other preprocessing for now."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Import the classifiers.py file from the first project\n",
      "\"\"\"\n",
      "import classifiers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2.1 Basic classification ##\n",
      "\n",
      "**Deliverable 1a** Using only the word itself as a feature (and an offset feature for each class), train your averaged perceptron and report the accuracy.\n",
      "If you successfully implemented MIRA in the last assignment, \n",
      "you may use that instead of averaged perceptron throughout this assignment.\n",
      "But if you are not successfully meeting the accuracies in the sanity check\n",
      "with MIRA, go back to Averaged Perceptron.\n",
      "\n",
      "**Advice:** I design feature functions that take two arguments: the entire input string (all tokens), \n",
      "and the index of the token to be tagged. \n",
      "The output can be a dict (with feature names as keys and counts as values), or a sparse vector.\n",
      "In either case, this general representation will allow you to implement more complex features later."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Deliverable 1b** Again using only the word itself, train your Naive Bayes classifier and report the accuracy. \n",
      "Use some non-zero alpha, for example $\\alpha = 0.01$.\n",
      "Or you can try a few alphas.\n",
      "\n",
      "**Sanity check**: I get roughly 67% accuracy with both classifiers."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2.2 More features ##\n",
      "\n",
      "Now you will add some more interesting features. Try at least the following:\n",
      "\n",
      "- The words to the left and right of the current word\n",
      "- A feature indicating if the word is capitalized\n",
      "- A feature indicating if the word is in Title case\n",
      "- The first character of the current word\n",
      "- The last character of the current word\n",
      "\n",
      "[This paper](http://www.ark.cs.cmu.edu/TweetNLP/gimpel+etal.acl11.pdf) has many more ideas for features that you could try."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Deliverable 2 ** Add (at least) these features to your averaged perceptron (or MIRA),\n",
      "and plot the accuracy versus iterations on the dev and training data.\n",
      "Run for at least ten iterations. You may want to keep running if training accuracy is still improving.\n",
      "\n",
      "** Sanity check **: I get above 80% accuracy with these features."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*(Explain what you did)*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2.3 Evaluation: recall and precision ##\n",
      "\n",
      "Now we want to see how well we are classifying each individual tag. We need to distinguish two kinds of mistakes:\n",
      "\n",
      "- **F**alse **N**egatives (FN): we should have predicted a tag, but we didn't; and\n",
      "- **F**alse **P**ositive (FP): we predicted the tag, but it wasn't applicable.\n",
      "\n",
      "**T**rue **P**ositive (TP) is when we predict a tag, and it was correct. \n",
      "\n",
      "Using these counts, we can compute each tag's **precision** and **recall**. We can then combine the precision and recall into a single\n",
      "**F-measure**.\n",
      "\n",
      "Recall: $$R_t=\\frac{TP_t}{TP_t+FN_t}$$\n",
      "\n",
      "Precision: $$P_t=\\frac{TP_t}{TP_t+FP_t}$$\n",
      "\n",
      "F-measure: $$F_t=\\frac{2R_tP_t}{R_t+P_t}$$\n",
      "\n",
      "where $TP_t$, $FP_t$ and $FN_t$ are true positives, false positives and false negatives of tag $t$ respectively. [This wiki page](http://en.wikipedia.org/wiki/Precision_and_recall) provides more detail about related concepts."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Deliverable 3 ** What tag pair produces the greatest number of errors? What gets the lowest F-measure? \n",
      "\n",
      "Using the confusion matrix from the previous task, compute each tag's recall, precision, and F-measure."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here for recall/precision/f-measure"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*(Explain what you observed)*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 3 Viterbi Algorithm #\n",
      "\n",
      "In this section you will implement the Viterbi algorithm. To get warmed up, let's work out an example by hand. These are only two tags, \n",
      "N and V. Here are the parameters:\n",
      "\n",
      "| | Value |\n",
      "| ------------- |:-------------:|\n",
      "| $\\log P_E(\\cdot|N)$ | they: -1, can: -3, fish: -3 |\n",
      "| $\\log P_E(\\cdot|V)$ | they: -10, can: -2, fish: -3 |\n",
      "| $\\log P_T(\\cdot|N)$ | N: -5, V: -2, END: -2 |\n",
      "| $\\log P_T(\\cdot|V)$ | N: -1, V: -4, END: -3 |\n",
      "| $\\log P_T(\\cdot|\\text{START})$ | N :-1, V :-1 |\n",
      "\n",
      "where $P_E(\\cdot|\\cdot)$ is the emission probability and $P_T(\\cdot|\\cdot)$ is the translation probability.\n",
      " \n",
      " In class we discuss the sentence *They can fish*. Now work out a more complicated example: \"*They can can fish*\"."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Deliverable 4 ** Work out the viterbi algorithm by hand, and fill in the\n",
      "values in the following table.\n",
      "\n",
      "** Sanity check ** There are two paths that each score -18."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*(Fill your answer in the following table)*\n",
      "\n",
      "|POS tag| START  | they | can | can | fish | END |\n",
      "|-------|:-------|:-----|:----|:----|:-----|:---:|\n",
      "| N     |    0   |      |     |     |      | -18 |\n",
      "| V     |    0   |      |     |     |      | -18 |"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Example** Taking one trellis used in the class slides as an example\n",
      "\n",
      "<img src=\"files/trellis.png\">\n",
      "\n",
      "The corresponding trellis-like table is \n",
      "\n",
      "|POS tag| START  | they | can | fish | END |\n",
      "|-------|:-------|:-----|:----|:-----|:---:|\n",
      "| N     |    0   | -3   | -9  |  -9  | -11 |\n",
      "| V     |    0   | -12  | -5  |  -10 | -11 |"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, implement the Viterbi algorithm. You will want to be able to specify arbitrary weights between words and tags, \n",
      "and between pairs of tags. There are lots and lots of pseudocode (and real code) examples of this online, for example, \n",
      "[the wiki page](http://en.wikipedia.org/wiki/Viterbi_algorithm#Pseudocode) of Viterbi algorithm. The course reading \n",
      "is also a good place to start.\n",
      "\n",
      "A recommended design idea is to have your code take two arguments:\n",
      "\n",
      "- An array of dictionaries, one for each position in the input, with each dictionary mapping from tags to emission log-probabilities (or emission weights). \n",
      "Note that you can compute this from a traditional emission probability distribution, or from a classifier.\n",
      "- An array of dictionaries, one for each tag, with each dictionary mapping from tags to transition log-probabilities"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Import your implementation of Viterbi decoding algorithm\n",
      "\"\"\"\n",
      "import viterbi"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Deliverable 5a ** Use your implementation to construct the trellis for the example above.\n",
      "\n",
      "** Sanity check ** The best scoring path should be the same as when you worked it out by hand."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# your code here for presenting the results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Deliverable 5b ** Use your implementation to tag the sequence \n",
      "\n",
      "\"*they can can can can can can fish*\". \n",
      "\n",
      "Report the best scoring tag sequence\n",
      "and the score."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# your code here for presenting the results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 4. Hidden Markov Models #\n",
      "\n",
      "Use maximum likelihood estimation to obtain transition and emission distribution from the training data. \n",
      "Since your Viterbi implementation will be additive, you need to take the logs of these probabilities. \n",
      "Let $\\alpha$ be the smoothing parameter for both the transitions and emissions."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Deliverable 6a ** For $\\alpha=0.01$, estimate the parameters from the training data, and run your algorithm on the dev data. Report \n",
      "the accuracy.\n",
      "\n",
      "** Sanity check **: I got roughly 75% accuracy from the HMM."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** Deliverable 6b ** Now try a range of at least 5 different $\\alpha$ value. Plot the resulting accuracy, with the $\\log(\\alpha)$ \n",
      "on the x-axis."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 5. Structured Perceptron #\n",
      "\n",
      "You will now train a structured perceptron. Recall that the basic update rule is:\n",
      "\n",
      "$$\\hat{y}=\\arg\\max_{y\\in\\mathcal{Y}_x}w^{\\top}f(x,y)\\quad (1)$$\n",
      "\n",
      "$$w^{(t)}\\leftarrow w^{(t-1)} + \\eta^{(t)}(f(x,y^{\\ast})-f(x,\\hat{y}))\\quad (2)$$\n",
      "where $\\mathcal{Y}_{x}$ is the set of all possible taggings for input $x,y^{\\ast}$ is the ground truth tagging, and $\\eta$ is a learning\n",
      "rate $(0<\\eta < 1)$.\n",
      "\n",
      "Your Viterbi algorithm can compute Equation (1), as long as the feature function $f(x,y)$ factors across edges. \n",
      "This means you can include any feature that either a single $y_i$ (with any subset of $x$) or $\\langle y_{i},y_{i+1}\\rangle$.\n",
      "\n",
      "After identifying $\\hat{y}$, you need to compute the two feature vectors, and update the weights for all the features that are affected.\n",
      "For the experiments, you should use either your averaged perceptron or MIRA (or both)\n",
      "\n",
      "** Sanity check ** Because you have to run Viterbi for each training example, this may be a little slow. \n",
      "In my case, it takes a little less than a minute per iteration.\n",
      "This means that you need to develop your code on a subset of the data, \n",
      "so that you don't wait 20 minutes to find a bug that you could fix in 10 seconds."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 5.1 Simple features ##\n",
      "\n",
      "Include the following features only:\n",
      "\n",
      "- Adjacent tag pairs $\\langle y_i,y_{i+1}\\rangle$\n",
      "- Word-tag pairs $\\langle y_i,x_i\\rangle$\n",
      "\n",
      "**Deliverable 7 ** Run the structured perceptron with these features for at least 20 iterations.\n",
      "Plot the performance on the training and dev set every five iterations (or more often).\n",
      "\n",
      "** Sanity check ** Your performance should be at least as good as the HMM, and at least as good as your averaged perceptron in deliverable 1."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 5.2 More features ##\n",
      "\n",
      "Now add additional features, including at least the character-based and capitalization features from the classification part of \n",
      "the assignment. You can optionally add the left and right neighbor word features if you can figure out how (there is nothing \n",
      "conceptually difficult about it, but it may make your implementation a little more complicated).\n",
      "\n",
      "** Deliverable 8 ** List additional features you used, explain what you think they will capture, \n",
      "and run the structured perceptron with these features. \n",
      "Plot performance on the training and dev sets every 5 iterations (or more often).\n",
      "\n",
      "** Sanity check ** Last year, my best system got above 85% accuracy on the dev set."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*(List additional features here)*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 6. Literature Review # \n",
      "\n",
      "**This part is optional for 4650, mandatory for 7650**\n",
      "\n",
      "** Deliverable 9 ** Find a research paper about supervised sequence labeling, for a task *other than* POS tagging. The paper should be \n",
      "published in the last ten years at one of the following venues: ACL, NAACL, EACL, EMNLP. Describe the following:\n",
      "\n",
      "- The basic information about this paper\n",
      "- The tag set\n",
      "- The learning algorithm\n",
      "- The features, and why they are expected to be effective\n",
      "- The difference from prior work. Is it a new task? A new learning algorithm? A new feature set? Something else?\n",
      "\n",
      "One way to search is to start with a machine learning paper (on conditional random fields or HMMs) and then use Google scholar \n",
      "to find applications papers that cite it. Or you can also directly search with some key words in the [ACL anthology](http://aclweb.org/anthology/)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*(Your answer here)*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 7. Bakeoff! #\n",
      "\n",
      "I will send out the test data roughly 48 hours before the deadline.\n",
      "\n",
      "** Deliverable 10 ** Run your (one) best system, and included it in your submission as **lastname-firstname.response**."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}